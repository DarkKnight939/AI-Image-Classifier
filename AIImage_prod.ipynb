{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX9lhUZJz5zZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import zipfile\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base model configuration (using a simplified version)\n",
        "base_model = [\n",
        "    [1, 16, 1, 1, 3],\n",
        "    [6, 24, 2, 2, 3],\n",
        "    [6, 40, 2, 2, 5],\n",
        "    [6, 80, 3, 2, 3],\n",
        "    [6, 112, 3, 1, 5],\n",
        "]\n",
        "\n",
        "phi_values = {\n",
        "    \"b0\": (0, 32, 0.2),\n",
        "    \"b1\": (1, 32, 0.2),\n",
        "    \"b2\": (2, 32, 0.3),\n",
        "    \"b3\": (3, 32, 0.3),\n",
        "    \"b4\": (4, 32, 0.4),\n",
        "}\n",
        "\n",
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, groups=1):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.cnn = nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, groups=groups)\n",
        "        self.bn = nn.BatchNorm2d(out_channel)\n",
        "        self.silu = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.silu(self.bn(self.cnn(x)))\n",
        "\n",
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(self, in_channel, reduced_dim):\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channel, reduced_dim, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(reduced_dim, in_channel, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.se(x)\n",
        "\n",
        "class InvertedResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, expand_ratio, reduction=4, survival_prob=0.8):\n",
        "        super(InvertedResidualBlock, self).__init__()\n",
        "        self.survival_prob = survival_prob\n",
        "        self.use_residual = in_channel == out_channel and stride == 1\n",
        "        hidden_dim = in_channel * expand_ratio\n",
        "        self.expand = in_channel != hidden_dim\n",
        "        reduced_dim = int(in_channel / reduction)\n",
        "\n",
        "        if self.expand:\n",
        "            self.expand_conv = CNNBlock(in_channel, hidden_dim, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            CNNBlock(hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim),\n",
        "            SqueezeExcitation(hidden_dim, reduced_dim),\n",
        "            nn.Conv2d(hidden_dim, out_channel, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channel)\n",
        "        )\n",
        "\n",
        "    def stochastic_depth(self, x):\n",
        "        if not self.training:\n",
        "            return x\n",
        "        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n",
        "        binary_tensor = binary_tensor.float()\n",
        "        return x / self.survival_prob * binary_tensor\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.expand_conv(inputs) if self.expand else inputs\n",
        "        if self.use_residual:\n",
        "            return self.stochastic_depth(self.conv(x)) + inputs\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self, version):\n",
        "        super(EfficientNet, self).__init__()\n",
        "        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n",
        "        last_channels = math.ceil(1280 * width_factor)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(last_channels, 512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU6(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def calculate_factors(self, version, alpha=1.2, beta=1.1):\n",
        "        phi, res, drop_rate = phi_values[version]\n",
        "        depth_factor = alpha ** phi\n",
        "        width_factor = beta ** phi\n",
        "        return width_factor, depth_factor, drop_rate\n",
        "\n",
        "    def create_features(self, width_factor, depth_factor, last_channels):\n",
        "        channels = int(32 * width_factor)\n",
        "        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]\n",
        "        in_channels = channels\n",
        "\n",
        "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n",
        "            out_channels = 4 * math.ceil(int(channels * width_factor) / 4)\n",
        "            layers_repeats = math.ceil(repeats * depth_factor)\n",
        "\n",
        "            for layer in range(layers_repeats):\n",
        "                features.append(\n",
        "                    InvertedResidualBlock(\n",
        "                        in_channels,\n",
        "                        out_channels,\n",
        "                        expand_ratio=expand_ratio,\n",
        "                        stride=stride if layer == 0 else 1,\n",
        "                        kernel_size=kernel_size,\n",
        "                        padding=kernel_size // 2\n",
        "                    )\n",
        "                )\n",
        "                in_channels = out_channels\n",
        "\n",
        "        features.append(\n",
        "            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "\n",
        "        return nn.Sequential(*features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.features(x))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        return self.fc_layers(x)\n"
      ],
      "metadata": {
        "id": "kJGjvsFP0AvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB9OdIDcC6Or",
        "outputId": "ca6235f7-bf8a-4fc3-d44c-196487dc3f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Path to the zip file and the destination folder for extraction\n",
        "zip_file_path = '/content/drive/MyDrive/web_scraped.zip'\n",
        "extraction_path = '/content/web_scraped_extracted'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# Define the transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize images to the input size for EfficientNet-B4\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the full dataset\n",
        "dataset_path = '/content/web_scraped_extracted/train'  # Updated to the correct path after extraction\n",
        "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Define function to get class indices\n",
        "def get_class_indices(dataset, class_name):\n",
        "    class_idx = dataset.class_to_idx[class_name]\n",
        "    indices = [i for i, (_, label) in enumerate(dataset.samples) if label == class_idx]\n",
        "    return indices\n",
        "\n",
        "# Get indices for the \"REAL\" and \"FAKE\" classes in the full dataset\n",
        "real_indices = get_class_indices(full_dataset, 'REAL')\n",
        "fake_indices = get_class_indices(full_dataset, 'FAKE')\n",
        "\n",
        "# Check the number of images in each class\n",
        "num_real_images = len(real_indices)\n",
        "num_fake_images = len(fake_indices)\n",
        "\n",
        "print(f\"Number of REAL images: {num_real_images}\")\n",
        "print(f\"Number of FAKE images: {num_fake_images}\")\n",
        "\n",
        "# Ensure we have 45,000 images per class\n",
        "if num_real_images >= 45000 and num_fake_images >= 45000:\n",
        "    # Randomly select 5000 indices from each class for the validation subset\n",
        "    real_val_selected = random.sample(real_indices, 5000)\n",
        "    fake_val_selected = random.sample(fake_indices, 5000)\n",
        "\n",
        "    # Combine the selected indices for the validation subset\n",
        "    val_selected_indices = real_val_selected + fake_val_selected\n",
        "\n",
        "    # Use the remaining indices for the training set\n",
        "    real_train_selected = [i for i in real_indices if i not in real_val_selected][:45000-5000]\n",
        "    fake_train_selected = [i for i in fake_indices if i not in fake_val_selected][:45000-5000]\n",
        "    train_selected_indices = real_train_selected + fake_train_selected\n",
        "\n",
        "    # Create the validation and training subsets\n",
        "    val_subset = Subset(full_dataset, val_selected_indices)\n",
        "    train_subset = Subset(full_dataset, train_selected_indices)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Print sizes of subsets\n",
        "    print(f\"Train dataset size: {len(train_subset)}\")\n",
        "    print(f\"Validation dataset size: {len(val_subset)}\")\n",
        "else:\n",
        "    print(\"Not enough images in one or both classes. Please ensure each class has at least 45,000 images.\")\n"
      ],
      "metadata": {
        "id": "qYceCDoT0KEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a96872-6e43-4cbf-8480-886baaeca6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of REAL images: 50000\n",
            "Number of FAKE images: 50000\n",
            "Train dataset size: 80000\n",
            "Validation dataset size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EfficientNet(version=\"b0\").to(device)\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/model (2).pth\", map_location=device))\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    # Training loop\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "    val_epoch_loss = val_loss / len(val_loader.dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "eHcm0VB_27Kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadda045-f058-4322-e997-f4d15ebd4d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1/20: 100%|██████████| 2500/2500 [01:56<00:00, 21.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Training Loss: 0.3145, Training Accuracy: 0.8665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 1/20: 100%|██████████| 313/313 [00:07<00:00, 39.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Validation Loss: 0.1972, Validation Accuracy: 0.9233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2/20: 100%|██████████| 2500/2500 [01:51<00:00, 22.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Training Loss: 0.2039, Training Accuracy: 0.9201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 2/20: 100%|██████████| 313/313 [00:08<00:00, 37.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Validation Loss: 0.1631, Validation Accuracy: 0.9416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3/20: 100%|██████████| 2500/2500 [01:51<00:00, 22.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Training Loss: 0.1707, Training Accuracy: 0.9362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 3/20: 100%|██████████| 313/313 [00:08<00:00, 37.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Validation Loss: 0.1550, Validation Accuracy: 0.9357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4/20: 100%|██████████| 2500/2500 [01:54<00:00, 21.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Training Loss: 0.1506, Training Accuracy: 0.9435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 4/20: 100%|██████████| 313/313 [00:07<00:00, 43.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Validation Loss: 0.1430, Validation Accuracy: 0.9440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Training Loss: 0.1336, Training Accuracy: 0.9497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 5/20: 100%|██████████| 313/313 [00:07<00:00, 39.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Validation Loss: 0.1337, Validation Accuracy: 0.9476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Training Loss: 0.1203, Training Accuracy: 0.9552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 6/20: 100%|██████████| 313/313 [00:08<00:00, 38.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Validation Loss: 0.1230, Validation Accuracy: 0.9544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Training Loss: 0.1072, Training Accuracy: 0.9599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 7/20: 100%|██████████| 313/313 [00:07<00:00, 40.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Validation Loss: 0.1185, Validation Accuracy: 0.9532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Training Loss: 0.0982, Training Accuracy: 0.9634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 8/20: 100%|██████████| 313/313 [00:08<00:00, 38.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Validation Loss: 0.1241, Validation Accuracy: 0.9499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Training Loss: 0.0843, Training Accuracy: 0.9694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 9/20: 100%|██████████| 313/313 [00:07<00:00, 44.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Validation Loss: 0.1354, Validation Accuracy: 0.9504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Training Loss: 0.0759, Training Accuracy: 0.9724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 10/20: 100%|██████████| 313/313 [00:08<00:00, 38.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Validation Loss: 0.1874, Validation Accuracy: 0.9286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 11/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Training Loss: 0.0658, Training Accuracy: 0.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 11/20: 100%|██████████| 313/313 [00:07<00:00, 44.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Validation Loss: 0.1578, Validation Accuracy: 0.9440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 12/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Training Loss: 0.0616, Training Accuracy: 0.9768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 12/20: 100%|██████████| 313/313 [00:08<00:00, 38.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Validation Loss: 0.1616, Validation Accuracy: 0.9552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 13/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Training Loss: 0.0538, Training Accuracy: 0.9804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 13/20: 100%|██████████| 313/313 [00:07<00:00, 41.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Validation Loss: 0.1540, Validation Accuracy: 0.9487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 14/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Training Loss: 0.0499, Training Accuracy: 0.9818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 14/20: 100%|██████████| 313/313 [00:07<00:00, 42.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Validation Loss: 0.1693, Validation Accuracy: 0.9501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 15/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Training Loss: 0.0430, Training Accuracy: 0.9839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 15/20: 100%|██████████| 313/313 [00:08<00:00, 38.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Validation Loss: 0.1498, Validation Accuracy: 0.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 16/20: 100%|██████████| 2500/2500 [01:47<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Training Loss: 0.0425, Training Accuracy: 0.9842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 16/20: 100%|██████████| 313/313 [00:06<00:00, 44.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Validation Loss: 0.1725, Validation Accuracy: 0.9428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 17/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Training Loss: 0.0387, Training Accuracy: 0.9860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 17/20: 100%|██████████| 313/313 [00:08<00:00, 38.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Validation Loss: 0.1675, Validation Accuracy: 0.9515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 18/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Training Loss: 0.0356, Training Accuracy: 0.9875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 18/20: 100%|██████████| 313/313 [00:07<00:00, 43.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Validation Loss: 0.1522, Validation Accuracy: 0.9519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 19/20: 100%|██████████| 2500/2500 [01:49<00:00, 22.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Training Loss: 0.0338, Training Accuracy: 0.9875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 19/20: 100%|██████████| 313/313 [00:08<00:00, 37.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Validation Loss: 0.1594, Validation Accuracy: 0.9531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 20/20: 100%|██████████| 2500/2500 [01:48<00:00, 23.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Training Loss: 0.0302, Training Accuracy: 0.9890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 20/20: 100%|██████████| 313/313 [00:07<00:00, 42.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Validation Loss: 0.1860, Validation Accuracy: 0.9533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/model_checkpoint.pth'\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "X4fTjrG8gxov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model testing\n",
        "\n",
        "# Switch the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Variables to keep track of test performance\n",
        "test_loss = 0.0\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "\n",
        "# List to store all predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Use the same loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='/content/web_scraped_extracted/test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "        total_test += labels.size(0)\n",
        "\n",
        "        # Store predictions and labels for further analysis if needed\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate average loss and accuracy\n",
        "test_epoch_loss = test_loss / len(test_loader.dataset)\n",
        "test_epoch_acc = correct_test / total_test\n",
        "\n",
        "print(f\"Test Loss: {test_epoch_loss:.4f}, Test Accuracy: {test_epoch_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "POv_tJPh7_hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4591fe40-3e72-4361-a7e6-92934ab34370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 625/625 [00:15<00:00, 39.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2084, Test Accuracy: 0.9471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_incorrect = 0\n",
        "\n",
        "for i in range(len(all_preds)):\n",
        "    if all_preds[i] != all_labels[i]:\n",
        "        num_incorrect += 1\n",
        "\n",
        "print(f\"Number of incorrect predictions: {num_incorrect}\")"
      ],
      "metadata": {
        "id": "4w-YMzWH9oQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02289a4b-2bb7-45af-fd9c-0e3137a938a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of incorrect predictions: 1058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_preds)"
      ],
      "metadata": {
        "id": "vcd-KHwYvwx_",
        "outputId": "5c3b9595-1390-42d0-a7ef-6e7be08d6e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}